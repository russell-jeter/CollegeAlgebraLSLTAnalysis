{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_excel(\"../question_database_schema.xlsx\", sheet_name=\"student_question_responses\")\n",
    "key_df = pd.read_excel(\"../question_database_schema.xlsx\", sheet_name=\"answer_choices\")\n",
    "key_df = key_df[key_df['is_distractor'] == 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create single exam/version df for Rasch modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions to form 0/1 dataframe with each row being a student and each column being a single exam/version question\n",
    "\n",
    "# Returns dataframe df with just rows with 'question_id' == num_and_ver\n",
    "def exam_num_ver_df(num_and_ver, df):\n",
    "    exam_mask = df.apply(lambda x: x['question_id'].startswith(num_and_ver), axis=1) # Applies lambda function searching for rows (axis=1) with 'question_id' = num_and_ver\n",
    "    exam_df = df[exam_mask]\n",
    "    return exam_df\n",
    "\n",
    "# Reorganizes student responses to a single exam into columns by question_id\n",
    "def questions_to_columns(df):\n",
    "    list_of_unique_id_dicts=[] # initalize empty list for future df\n",
    "    for unique_id in df['student_id'].unique(): # for each student \n",
    "        unique_id_df = df[df['student_id'] == unique_id] # reduce df to just the student responses on the exam\n",
    "        temp_dict={'id': unique_id} # initalize future row as a dict by student id\n",
    "\n",
    "        question_list = unique_id_df['question_id'].tolist() # list of question_ids for columns\n",
    "        selection_list = unique_id_df['selected_option'].tolist() # list of student responses by question_id\n",
    "        \n",
    "        for index in range(0, len(question_list)):\n",
    "            temp_dict[question_list[index]]=selection_list[index] # assign student response to each question_id for future row as a dict\n",
    "        \n",
    "        list_of_unique_id_dicts.append(temp_dict) # add future row as dict to list for future df\n",
    "\n",
    "    restructured_df=pd.DataFrame(list_of_unique_id_dicts) # create dataframe based on list of dicts as rows\n",
    "    restructured_df=restructured_df.set_index('id', drop=True) # set the student ids as the index and drop the old index\n",
    "    bad_question=['4A01', '4B01', '4C01'] # Exam 4 question 1 is \"what version exam do you have\" and is omitted from analysis\n",
    "    for bad_q_label in bad_question: # Removes bad questions from df\n",
    "        if bad_q_label in restructured_df.keys():\n",
    "            restructured_df.drop(bad_q_label, axis=1, inplace=True)\n",
    "    return restructured_df\n",
    "\n",
    "# Creates a key for the num_and_ver exam to be used for the correct/incorrect matrix\n",
    "def create_num_ver_key_dict(num_and_ver, key_df):\n",
    "    exam_key_df = exam_num_ver_df(num_and_ver, key_df) # Takes full key_df and reduces to key_df for just this num_and_ver\n",
    "    question_ids = exam_key_df['question_id'].tolist() # Creates list of question_ids \n",
    "\n",
    "    answer_series=exam_key_df['option_id'].replace({'A': '1', 'B': '2', 'C': '3', 'D': '4', 'E': '5'}) # avoids downcast warning\n",
    "    answer_series=answer_series.astype(int) # manually forces downcasting\n",
    "    answers = answer_series.tolist() # list of answers\n",
    "\n",
    "    key_dict = {} # initalize key dict\n",
    "    for index in range(0, len(question_ids)):\n",
    "        key_dict[question_ids[index]] = answers[index] # assign an answer to each question_id\n",
    "    return key_dict\n",
    "\n",
    "# Function for df.apply to compare whether a row is the same as another on some subset of the df \n",
    "# Used to compare key_dict to a student row\n",
    "def compare_row_to_dict(row, dict_to_compare):\n",
    "    return row.eq(pd.Series(dict_to_compare))\n",
    "\n",
    "# Creates 0/1 df by matching key_dict to each student's response\n",
    "def true_false_df(df, key_dict):\n",
    "    tf_df = df.apply(compare_row_to_dict, axis=1, args=(key_dict,)) # axis=1 for row matching, additional args for the key\n",
    "    return tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions to manipulate raw dfs to create dfs by exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove students & questions with 100% scores and 0% scores as these cause issues with ability and difficulty estimates\n",
    "def remove_issue_scores(df):\n",
    "    temp_df = df.copy()\n",
    "    len_of_key = len(df.keys()) # Used to check for total number of questions for exam\n",
    "    temp_df['score']=temp_df.sum(axis=1) # Column with student's total number of correct responses\n",
    "\n",
    "    if len_of_key in temp_df['score'].unique(): # If any students got every single question correct\n",
    "        drop_list_100s=temp_df[temp_df['score'] == len_of_key].index.to_list() # List of indicies for students who scored 100%\n",
    "        temp_df.drop(drop_list_100s, inplace=True) # Drop rows by indicies\n",
    "        #print(f'{len(drop_list_100s)} 100% scores were dropped.') \n",
    "    if 0 in temp_df['score'].unique(): # If any students got no question correct\n",
    "        drop_list_0s=temp_df[temp_df['score'] == 0].index.to_list() \n",
    "        temp_df.drop(drop_list_0s, inplace=True) # List of indicies for students who scored 0%\n",
    "        #print(f'{len(drop_list_0s)} 0% scores were dropped.')\n",
    "    temp_df.drop(['score'], axis=1, inplace=True) # Drop rows by indicies\n",
    "\n",
    "    question_score_series=temp_df.mean(axis=0) # Series to check for 100% and 0% scores by question (axis=0 for columns)\n",
    "    \n",
    "    question_0_score_series=question_score_series.where(question_score_series == 0).dropna() # Returns reduced series where average response to question was 0 (which implies all students got it wrong or omitted)\n",
    "    if len(question_0_score_series) > 0:\n",
    "        q0_index_list=question_0_score_series.index.to_list() # List of indicies for questions with scores 0%\n",
    "        temp_df.drop(q0_index_list, axis=1, inplace=True) # Drop columns by indicies, but column names are now rows of the Series\n",
    "\n",
    "    question_100_score_series=question_score_series.where(question_score_series == 1).dropna() # Returns reduced series where average response to question was 1 (which implies all students got it right or omitted)\n",
    "    if len(question_100_score_series) > 0:\n",
    "        q100_index_list=question_100_score_series.index.to_list() # List of indicies for questions with scores 100%\n",
    "        temp_df.drop(q100_index_list, axis=1, inplace=True) # Drop columns by indicies, but column names are now rows of the Series\n",
    "\n",
    "    return temp_df\n",
    "\n",
    "# Defines list of all exam numbers [character 1] and exam forms [character 2]\n",
    "def collect_all_exam_numbers_and_forms(df):\n",
    "    all_question_ids=df['question_id'].tolist()\n",
    "    all_exam_numbers_and_forms=list(set([x[0:2] for x in all_question_ids])) # list comprehension for first two characters of question_id list, then cast to set for uniqueness, then returned to list\n",
    "    return all_exam_numbers_and_forms\n",
    "\n",
    "def create_true_false_for_all_exams(full_df, key_df, all_exam_numbers_and_forms):\n",
    "    list_of_tf_dfs=[] # initialize future list of true/false dfs for Rasch model\n",
    "    for exam_num_and_form in all_exam_numbers_and_forms:\n",
    "        temp_exam_df=exam_num_ver_df(exam_num_and_form, full_df) # temp df based on exam number and form\n",
    "        temp_exam_responses_df=questions_to_columns(temp_exam_df) # convert to students by row with question_ids as columns\n",
    "        temp_exam_answer_key=create_num_ver_key_dict(exam_num_and_form, key_df) # create answer key for scoring student responses\n",
    "        temp_exam_tf_df=true_false_df(temp_exam_responses_df, temp_exam_answer_key).astype(int) # score student responses with answer key\n",
    "        list_of_tf_dfs.append({'exam_num_and_form': exam_num_and_form, 'true_false_df': temp_exam_tf_df}) # return 0/1 df by name\n",
    "    return list_of_tf_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions for Rasch calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for df.apply() to create ability estimate by row\n",
    "def ability_estimate(row):\n",
    "    return math.log(row['avg_student_score'] / (1 - row['avg_student_score']))\n",
    "\n",
    "# Function for df.apply() to create difficulty estimate by column\n",
    "def difficulty_estimate(col):\n",
    "    return math.log((1 - col['avg_question_score'] ) / col['avg_question_score'])\n",
    "\n",
    "# Calculuate ability and difficulty estimates based on 0/1 df\n",
    "def approximate_ability_and_difficulty(df):\n",
    "    temp_df=df.copy() # creates a copy just in case \n",
    "    temp_df['avg_student_score']=temp_df.mean(axis=1) # mean by row, where mean of 0/1s is overall score on exam\n",
    "    theta_s=temp_df.apply(ability_estimate, axis=1).tolist() # df.apply returns a single value based on the row, which would be a Series that we convert to list\n",
    "    temp_df.drop(['avg_student_score'], axis=1, inplace=True) # drop the 'avg_student_score' so a difficulty estimate is not made based on the column\n",
    "\n",
    "    temp_df.loc['avg_question_score']=temp_df.mean(axis=0) # mean by column, where mean of 0/1s is overall score on question\n",
    "    beta_i_non_normal=temp_df.apply(difficulty_estimate, axis=0) # df.apply returns a single value based on the column, returns as Series\n",
    "    # temp_df.drop(['avg_question_score'], inplace=True) # depreciated since df no longer returned\n",
    "    avg_beta_i=beta_i_non_normal.mean() # calculates average beta_i (difficulty estimate for item i) to normalize\n",
    "    beta_i=beta_i_non_normal - avg_beta_i # normalizes difficulty estimates\n",
    "    beta_i_keys=beta_i.keys().tolist() # Question names for dict keys, needed for calc_expected_values function\n",
    "    return {'beta_i_keys': beta_i_keys, 'beta_i': beta_i, 'theta_s': theta_s} # returns ability and difficulty estimate with question_id keys for future columns\n",
    "\n",
    "# If error is too large, adjust beta_i and theta_s by sum of error / sum of variance \n",
    "def iterate_variable_estimates(variable_estimates_dict, variance_df, residuals_df):\n",
    "    beta_i=variable_estimates_dict['beta_i']\n",
    "    theta_s=variable_estimates_dict['theta_s']\n",
    "    beta_i_keys=variable_estimates_dict['beta_i_keys'] # Not used in this function but is returned for new variable_estimates_dict\n",
    "\n",
    "    new_beta_i=[]\n",
    "    for beta_index in range(0, len(beta_i)):\n",
    "        col_names=variance_df.columns.tolist() # Track column names by variance_df (which matches residuals_df) in case questions were thrown out due to 100% or 0%\n",
    "        temp_key=col_names[beta_index] # question_i associated to beta_i\n",
    "        residual_col_sum=residuals_df[temp_key].sum() # sum of residuals by column (i)\n",
    "        variance_col_sum=variance_df[temp_key].sum() # sum of variance by column (i)\n",
    "        temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
    "        new_beta_i.append(temp_new_beta) \n",
    "\n",
    "    new_theta_s=[]\n",
    "    for theta_index in range(0, len(theta_s)):\n",
    "        index_names=variance_df.index.values.tolist() # Uses variance_df indicies in case students were thrown out due to 100% or 0%\n",
    "        temp_index=index_names[theta_index] # student_s associated with theta_s\n",
    "        residual_row_sum=residuals_df.loc[temp_index].sum() # sum of residuals by student (s)\n",
    "        variance_row_sum=variance_df.loc[temp_index].sum() # sum of variance by student (s)\n",
    "        new_theta = theta_s[theta_index] + (residual_row_sum / variance_row_sum) # new estimate is old theta_s - sum of error by row / variance by row\n",
    "        new_theta_s.append(new_theta)\n",
    "\n",
    "    beta_mean=statistics.fmean(new_beta_i) # convert all values to float-type then compute mean, faster than .mean\n",
    "    new_beta_i=[x-beta_mean for x in new_beta_i] # normalizes difficulty estimates, as before\n",
    "\n",
    "    return {'beta_i': new_beta_i, 'theta_s': new_theta_s, 'beta_i_keys': beta_i_keys}\n",
    "\n",
    "# Expected values are the probability of student s answering question i correctly given a student's ability score theta_i and the item's difficulty beta_i\n",
    "# Matched against student responses (1/0) on exam\n",
    "def calc_expected_values(variable_estimates_dict):\n",
    "    beta_i_keys=variable_estimates_dict['beta_i_keys']\n",
    "    beta_i=variable_estimates_dict['beta_i']\n",
    "    theta_s=variable_estimates_dict['theta_s']\n",
    "\n",
    "    list_of_ev_dicts=[]\n",
    "    # Iterrate by rows, then by columns to create each entry\n",
    "    for theta_index in range(0, len(theta_s)):\n",
    "        temp_ev_dict={} # initalize new row for theta_index\n",
    "        for beta_index in range(0, len(beta_i)): # iterate by column to create row dict\n",
    "            exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
    "            temp_ev_dict[beta_i_keys[beta_index]] = exp_vars / (1 + exp_vars) # probability of student s answering question i correctly given a student's ability score theta_i and the item's difficulty beta_i\n",
    "        list_of_ev_dicts.append(temp_ev_dict) \n",
    "\n",
    "    ev_df=pd.DataFrame(list_of_ev_dicts)\n",
    "    return ev_df\n",
    "\n",
    "# Calculates variance dataframe for itereate_variable_estimates function\n",
    "def calc_est_var(df):\n",
    "    return df.apply(lambda x: x*(1-x)) # variance of binomial distribution is n*p*(1-p), where n=1 for variance of a single (_i)(_s) entry\n",
    "\n",
    "# function to find sum of squares by row (equal to sum of squares by column)\n",
    "def calc_sum_sqr_residuals(df):\n",
    "    temp_series_sum = df.sum(axis=1) # sum by row (axis=1)\n",
    "    temp_series_sum = temp_series_sum.pow(2) # .pow(n) raises each Series entry to the nth power\n",
    "    sum_of_sqrs = temp_series_sum.sum() # sum the squares of each Series entry\n",
    "    return sum_of_sqrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasch calculation definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rasch_model(base_df):\n",
    "    student_ids=base_df.index.tolist() # Save student_ids to apply at end\n",
    "    first_iteration=1 # first iteration will approximate ability and difficulty, all others will iterate the variables\n",
    "    sum_sqr_res=1 # forces while to fail on first iteration and is calculated later\n",
    "    iteration_num=0 # only used for testing\n",
    "    while sum_sqr_res > 0.0001: # while sum of errors is \"large\"\n",
    "        if first_iteration==1:\n",
    "            iteration_num=1 # only used for testing\n",
    "            first_iteration=0 # forces future iterations to iterate on future ability and difficulty estimates\n",
    "            variable_estimates_dict=approximate_ability_and_difficulty(base_df) # initial ability estimates by student and difficulty estimates by item\n",
    "        else:\n",
    "            iteration_num+=1\n",
    "            variable_estimates_dict=iterate_variable_estimates(variable_estimates_dict, est_var_ex_vals_df, residuals_df) # modifies ability and difficulty estimates by giving more weight to ability and less to difficulty\n",
    "        expected_values_df=calc_expected_values(variable_estimates_dict) # probability a student s answers question i correctly\n",
    "        est_var_ex_vals_df=calc_est_var(expected_values_df) # variance of expected values as 1*p*(1-p)\n",
    "        base_df.index=expected_values_df.index # ensure indicies between base_df and expected_values_df are equal for subtraction of dfs\n",
    "        residuals_df=base_df-expected_values_df # difference between actual response scores and probability based on student ability and item difficulty\n",
    "        sum_sqr_res=calc_sum_sqr_residuals(residuals_df) # sum of errors between actual response scores and probability\n",
    "\n",
    "    fit_df=residuals_df.pow(2)/est_var_ex_vals_df # final normalized error for each expected value\n",
    "    fit_df.index=student_ids # applies original index of base_df\n",
    "\n",
    "    var_estimates_students=pd.Series(variable_estimates_dict['theta_s'], index=student_ids) # variance for ability estimates by student\n",
    "    var_estimates_items=pd.Series(variable_estimates_dict['beta_i'], index=variable_estimates_dict['beta_i_keys']) # variance for difficulty estimates by item\n",
    "\n",
    "    # Outfit (Outlier-Sensitivity fit) Unweighted Fit Mean Square\n",
    "    # Sensitive to \"outer\" outliers (difficulty and ability far apart)\n",
    "    outfit_students=fit_df.mean(axis=1) \n",
    "    outfit_students.index=student_ids\n",
    "    outfit_items=fit_df.mean(axis=0)\n",
    "\n",
    "    # Infit (Inlier-Sensitivity fit) Weighted Fit Mean Square\n",
    "    # Sensitive to \"inner\" outliers (unexpected performance on items at student difficulty level)\n",
    "    infit_students=residuals_df.pow(2).sum(axis=1)/est_var_ex_vals_df.sum(axis=1) # Weighted by variance\n",
    "    infit_students.index=student_ids\n",
    "    infit_items=residuals_df.pow(2).sum(axis=0)/est_var_ex_vals_df.sum(axis=0) # Weighted by variance\n",
    "\n",
    "    bad_infit_items=infit_items.where(infit_items > 1.3).dropna()\n",
    "    bad_infit_students=infit_students.where(infit_students > 1.3).dropna()\n",
    "\n",
    "    bad_outfit_items=outfit_items.where(outfit_items > 1.3).dropna()\n",
    "    bad_outfit_students=outfit_students.where(outfit_students > 1.3).dropna()\n",
    "\n",
    "    return {'fit_df': fit_df, \n",
    "            'var_estimates_students': var_estimates_students, \n",
    "            'var_estimates_items': var_estimates_items, \n",
    "            'outfit_students': outfit_students, \n",
    "            'outfit_items': outfit_items,\n",
    "            'infit_students': infit_students,\n",
    "            'infit_items': infit_items,\n",
    "            'bad_infit_items': bad_infit_items,\n",
    "            'bad_infit_students': bad_infit_students, \n",
    "            'bad_outfit_items': bad_outfit_items,\n",
    "            'bad_outfit_students': bad_outfit_students\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Rasch for all exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:64: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index]) # Rasch model of 1PL with alpha=1\n",
      "C:\\Users\\dcham\\AppData\\Local\\Temp\\ipykernel_5280\\3759183840.py:36: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum) # new estimate is old beta_i - sum of error by column / variance by column\n"
     ]
    }
   ],
   "source": [
    "all_exam_numbers_and_forms=collect_all_exam_numbers_and_forms(raw_df)\n",
    "list_of_tf_dfs=create_true_false_for_all_exams(raw_df, key_df, all_exam_numbers_and_forms)\n",
    "\n",
    "list_of_rasch_dicts=[]\n",
    "for exam_df in list_of_tf_dfs:\n",
    "    no_error_exam_df=remove_issue_scores(exam_df['true_false_df'])\n",
    "    rasch_dict=build_rasch_model(no_error_exam_df)\n",
    "    rasch_dict['exam_num_and_form']=exam_df['exam_num_and_form']\n",
    "    rasch_dict['true_false_df']=exam_df['true_false_df']\n",
    "    list_of_rasch_dicts.append(rasch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3C06    1.339928\n",
      "dtype: float64\n",
      "3634462     1.531275\n",
      "9661400     1.443092\n",
      "11871185    1.531275\n",
      "14591907    1.531275\n",
      "15830791    1.555520\n",
      "15917802    1.473189\n",
      "16961601    1.355046\n",
      "17437695    1.339491\n",
      "18927351    1.597956\n",
      "35858306    1.481639\n",
      "36514549    1.596940\n",
      "57597189    1.650365\n",
      "63312335    1.458860\n",
      "69542440    1.496051\n",
      "97887921    1.419768\n",
      "dtype: float64\n",
      "3C06    2.595868\n",
      "3C08    1.505799\n",
      "dtype: float64\n",
      "3634462     2.429643\n",
      "9661400     1.402347\n",
      "11871185    2.429643\n",
      "14591907    2.429643\n",
      "14865762    2.262519\n",
      "15830791    3.780883\n",
      "15917802    1.557513\n",
      "18863085    1.542314\n",
      "35858306    2.398051\n",
      "36514549    2.590849\n",
      "57597189    1.548059\n",
      "81211521    1.306045\n",
      "91851188    1.534696\n",
      "dtype: float64\n",
      "\n",
      "2A01    1.349703\n",
      "dtype: float64\n",
      "12919965    1.394735\n",
      "15941175    1.308665\n",
      "35535110    1.322200\n",
      "42178510    1.467887\n",
      "44048916    1.451428\n",
      "47694846    1.453334\n",
      "58005517    1.322843\n",
      "64881777    1.744520\n",
      "81834450    1.370512\n",
      "81904079    1.302459\n",
      "dtype: float64\n",
      "2A01    1.608831\n",
      "2A07    1.801286\n",
      "dtype: float64\n",
      "7913559     1.397890\n",
      "12919965    3.965818\n",
      "15941175    1.589840\n",
      "21901863    3.144593\n",
      "24045109    1.387861\n",
      "30140523    1.467181\n",
      "35535110    1.380831\n",
      "38035938    1.414029\n",
      "42178510    1.991795\n",
      "44048916    1.694976\n",
      "47694846    1.378501\n",
      "58005517    1.412008\n",
      "64881777    2.085258\n",
      "81834450    1.350530\n",
      "81904079    1.344820\n",
      "dtype: float64\n",
      "\n",
      "Series([], dtype: float64)\n",
      "3290988     1.472421\n",
      "7493959     1.465242\n",
      "10149322    1.311392\n",
      "14987391    1.362692\n",
      "17954414    1.408476\n",
      "26307414    1.690283\n",
      "32818187    1.584572\n",
      "35535110    1.488720\n",
      "51007936    1.475474\n",
      "61729177    1.613394\n",
      "61889908    1.310903\n",
      "62908046    1.314401\n",
      "65636549    1.338636\n",
      "81834450    1.674537\n",
      "83435565    1.398274\n",
      "89465108    1.346246\n",
      "93253491    1.396227\n",
      "97696019    1.491593\n",
      "dtype: float64\n",
      "1A05    1.334677\n",
      "1A06    1.473909\n",
      "dtype: float64\n",
      "3290988     3.028326\n",
      "7493959     1.534035\n",
      "14987391    1.607908\n",
      "17954414    1.475962\n",
      "26307414    4.029726\n",
      "32818187    2.116128\n",
      "35535110    1.440170\n",
      "51007936    1.385885\n",
      "57172791    1.368023\n",
      "61729177    1.644679\n",
      "62908046    1.516726\n",
      "63292062    1.511789\n",
      "63312335    1.326707\n",
      "65636549    1.430354\n",
      "81834450    5.045436\n",
      "83435565    1.677019\n",
      "89465108    2.280629\n",
      "97696019    1.852796\n",
      "dtype: float64\n",
      "\n",
      "Series([], dtype: float64)\n",
      "14912309    1.327686\n",
      "17922917    1.364403\n",
      "19361270    1.451559\n",
      "26307414    1.370989\n",
      "34836375    1.498902\n",
      "42394523    1.321432\n",
      "51941565    1.454799\n",
      "79512547    1.320846\n",
      "95799545    1.503127\n",
      "dtype: float64\n",
      "2B02    1.408242\n",
      "2B12    1.400127\n",
      "dtype: float64\n",
      "14912309    1.363879\n",
      "17922917    1.520445\n",
      "19361270    1.463237\n",
      "23136659    1.367509\n",
      "26307414    1.409318\n",
      "33984225    1.321172\n",
      "34836375    1.626716\n",
      "36514549    1.305106\n",
      "51941565    2.180064\n",
      "57172791    1.304469\n",
      "65841008    1.552319\n",
      "79512547    1.378983\n",
      "84960036    1.437859\n",
      "91579986    1.351583\n",
      "91802235    2.355754\n",
      "95799545    2.259638\n",
      "dtype: float64\n",
      "\n",
      "4B19    1.357873\n",
      "dtype: float64\n",
      "9661400     1.775552\n",
      "14591907    1.643426\n",
      "16961601    1.347462\n",
      "26953119    1.387126\n",
      "42178510    1.615369\n",
      "43986969    1.383427\n",
      "49198858    1.517472\n",
      "51253656    1.720832\n",
      "51981191    2.113758\n",
      "72569790    1.340024\n",
      "79175413    1.304823\n",
      "89211916    1.434722\n",
      "91851188    1.520417\n",
      "dtype: float64\n",
      "4B07    1.325245\n",
      "4B18    1.733079\n",
      "4B19    1.357570\n",
      "4B26    4.318201\n",
      "dtype: float64\n",
      "9661400     11.539026\n",
      "10149322     3.230206\n",
      "16961601     2.868991\n",
      "17954414     2.492571\n",
      "41436960     3.632025\n",
      "42178510     2.251263\n",
      "43986969     1.379151\n",
      "49198858     2.180289\n",
      "51253656     2.347476\n",
      "51981191     2.145825\n",
      "60346749     2.560683\n",
      "72569790     1.370657\n",
      "89211916     1.421504\n",
      "91851188     1.526035\n",
      "dtype: float64\n",
      "\n",
      "Series([], dtype: float64)\n",
      "15830791    1.387241\n",
      "22339090    1.397910\n",
      "30140523    1.466264\n",
      "33984325    1.444599\n",
      "37630731    1.389634\n",
      "91832157    1.343761\n",
      "91872768    1.665033\n",
      "dtype: float64\n",
      "4C06    1.437273\n",
      "4C10    1.587924\n",
      "4C18    1.626623\n",
      "dtype: float64\n",
      "15830791    1.437723\n",
      "30140523    1.413329\n",
      "33984325    1.752167\n",
      "39618410    1.654311\n",
      "44953420    1.305362\n",
      "57597189    1.322269\n",
      "62908046    1.364749\n",
      "73711863    1.514210\n",
      "78141490    2.173953\n",
      "81118181    3.061471\n",
      "89465108    1.334654\n",
      "9149        1.451663\n",
      "91832157    1.758280\n",
      "91872768    2.086213\n",
      "dtype: float64\n",
      "\n",
      "2C01    1.526281\n",
      "2C06    1.351155\n",
      "dtype: float64\n",
      "9661400     1.558361\n",
      "18976900    1.391239\n",
      "32818187    1.338654\n",
      "59758143    1.391717\n",
      "71115498    1.394654\n",
      "91496313    1.442152\n",
      "91872768    1.652711\n",
      "dtype: float64\n",
      "2C01    1.836479\n",
      "2C06    1.455546\n",
      "2C09    1.310950\n",
      "dtype: float64\n",
      "9661400     1.733067\n",
      "10181571    1.360629\n",
      "13421997    1.350522\n",
      "16561848    2.319856\n",
      "18976900    1.444642\n",
      "32818187    1.746149\n",
      "51870924    3.068620\n",
      "59758143    1.382516\n",
      "71115498    3.235716\n",
      "81118181    1.623854\n",
      "91455147    1.412889\n",
      "91496313    1.590536\n",
      "91872768    1.791206\n",
      "dtype: float64\n",
      "\n",
      "Series([], dtype: float64)\n",
      "2905547     1.327394\n",
      "13030101    2.641312\n",
      "15300931    1.696716\n",
      "17954414    1.765615\n",
      "19361270    1.324313\n",
      "84960036    2.682939\n",
      "91579986    1.317021\n",
      "96834233    2.025921\n",
      "dtype: float64\n",
      "3B07    1.309744\n",
      "3B08    3.723936\n",
      "3B10    1.444908\n",
      "3B16    1.440062\n",
      "dtype: float64\n",
      "7913559      1.450197\n",
      "11963986     2.333335\n",
      "13030101     2.236483\n",
      "13421997     1.316078\n",
      "15300931     4.737491\n",
      "17954414     2.255954\n",
      "18513675     1.979328\n",
      "31217101     1.303193\n",
      "37630731     1.738758\n",
      "43986969     1.450197\n",
      "61729177     2.333335\n",
      "65195273     3.439712\n",
      "84960036     3.562813\n",
      "91579986     1.376797\n",
      "96834233    14.375970\n",
      "dtype: float64\n",
      "\n",
      "3A05    1.301043\n",
      "dtype: float64\n",
      "8367350     1.690695\n",
      "11974421    1.479974\n",
      "18891808    1.925590\n",
      "34595459    1.963389\n",
      "46464110    1.310084\n",
      "51196542    1.948862\n",
      "51941565    1.956514\n",
      "56151761    1.646918\n",
      "60164069    1.386745\n",
      "63292062    1.386745\n",
      "63675931    1.691524\n",
      "68549041    1.540732\n",
      "71115498    1.818222\n",
      "81118181    1.386745\n",
      "90482441    1.718780\n",
      "dtype: float64\n",
      "3A01    1.509550\n",
      "3A05    2.213106\n",
      "3A06    1.488285\n",
      "3A13    5.663023\n",
      "dtype: float64\n",
      "6129891      1.448676\n",
      "8367350     24.993477\n",
      "11974421     1.471178\n",
      "18891808     1.492395\n",
      "19069857     3.974900\n",
      "23855903     2.822787\n",
      "34595459     1.748651\n",
      "34836375     1.731481\n",
      "42178510     1.487071\n",
      "44953420     1.700730\n",
      "46464110     1.614028\n",
      "51196542     1.696414\n",
      "51941565     3.058791\n",
      "63675931     1.637029\n",
      "90482441     2.222704\n",
      "91885395     6.533704\n",
      "dtype: float64\n",
      "\n",
      "4A07    1.392307\n",
      "dtype: float64\n",
      "6129891     1.933279\n",
      "10874845    1.550743\n",
      "11140926    1.346581\n",
      "11963986    1.599673\n",
      "15553851    2.325810\n",
      "17922917    1.506249\n",
      "18927351    1.341843\n",
      "35858306    1.494607\n",
      "47694846    1.443132\n",
      "4809496     1.838195\n",
      "51196542    1.436010\n",
      "66897549    1.320939\n",
      "68549045    1.750871\n",
      "81834451    1.465451\n",
      "81904079    1.379698\n",
      "9318        1.419950\n",
      "97686953    1.386873\n",
      "dtype: float64\n",
      "4A08    2.001954\n",
      "4A10    2.077470\n",
      "4A19    2.992287\n",
      "dtype: float64\n",
      "6129891     2.063571\n",
      "10874845    1.303060\n",
      "11871185    1.869538\n",
      "11963986    1.356098\n",
      "15553851    4.710989\n",
      "17922917    3.797846\n",
      "18927351    1.627470\n",
      "35858306    1.911433\n",
      "44048916    1.678473\n",
      "47694846    2.287612\n",
      "4809496     1.944549\n",
      "66897549    1.893085\n",
      "68549045    2.562455\n",
      "81834451    1.425654\n",
      "81904079    4.771850\n",
      "91952581    1.385708\n",
      "dtype: float64\n",
      "\n",
      "Series([], dtype: float64)\n",
      "14912309    1.417345\n",
      "15553851    1.469786\n",
      "16561848    1.302931\n",
      "195273      1.486008\n",
      "21531511    1.360835\n",
      "21901863    1.550139\n",
      "23433808    1.310100\n",
      "23754837    1.750456\n",
      "28918672    1.359075\n",
      "42178510    1.501011\n",
      "69381183    1.345624\n",
      "72569790    1.578516\n",
      "73711863    1.403877\n",
      "79512547    1.347172\n",
      "81815775    1.616899\n",
      "83465143    1.333434\n",
      "97887921    1.315228\n",
      "98189834    1.408019\n",
      "dtype: float64\n",
      "1B10    1.483034\n",
      "dtype: float64\n",
      "6129891     1.450797\n",
      "9661400     1.667347\n",
      "10874845    1.329784\n",
      "14912309    1.379237\n",
      "15553851    1.998850\n",
      "17922917    1.549006\n",
      "195273      1.824045\n",
      "21531511    1.606582\n",
      "21901863    2.104870\n",
      "23754837    1.927982\n",
      "28918672    2.430289\n",
      "32074310    1.704935\n",
      "39667664    1.347724\n",
      "42178510    1.712228\n",
      "46464110    1.612509\n",
      "52614065    1.329784\n",
      "72569790    1.600016\n",
      "73711863    1.648641\n",
      "81815775    1.590838\n",
      "98189834    1.603936\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rasch_dict in list_of_rasch_dicts:\n",
    "    print(rasch_dict['bad_infit_items'])\n",
    "    print(rasch_dict['bad_infit_students'])\n",
    "    print(rasch_dict['bad_outfit_items'])\n",
    "    print(rasch_dict['bad_outfit_students'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_df':               3C02      3C03      3C04      3C05       3C06      3C07  \\\n",
       " 3204944   0.016534  0.052234  0.010634  0.386534   0.069696  0.016534   \n",
       " 3634462   0.006324  0.019978  0.004067  0.147840  37.513667  0.006324   \n",
       " 7942838   0.050025  0.158037  0.032175  1.169490   0.210870  0.050025   \n",
       " 9661400   2.417880  0.765361  0.266004  0.103425   1.743371  0.413585   \n",
       " 11140926  0.108322  0.342203  0.069669  0.394892   0.456604  0.108322   \n",
       " ...            ...       ...       ...       ...        ...       ...   \n",
       " 93253491  0.006324  0.019978  0.004067  0.147840   0.026657  0.006324   \n",
       " 93693198  0.050025  6.327642  0.032175  1.169490   0.210870  0.050025   \n",
       " 95714813  0.006324  0.019978  0.004067  6.764052   0.026657  0.006324   \n",
       " 97686953  0.050025  0.158037  0.032175  0.855073   0.210870  0.050025   \n",
       " 97887921  0.006324  0.019978  0.004067  0.147840   0.026657  0.006324   \n",
       " \n",
       "               3C08      3C09      3C10      3C11      3C12      3C13  \\\n",
       " 3204944   0.044221  0.052234  0.148776  0.022832  6.141638  0.486748   \n",
       " 3634462   0.016914  0.019978  0.056903  0.008733  0.062276  0.785779   \n",
       " 7942838   0.133796  6.327642  2.221563  0.069079  0.492634  0.160878   \n",
       " 9661400   0.904030  0.765361  0.268709  1.750972  4.072865  0.019459   \n",
       " 11140926  0.289712  0.342203  1.025966  0.149579  0.937455  0.074297   \n",
       " ...            ...       ...       ...       ...       ...       ...   \n",
       " 93253491  0.016914  0.019978  0.056903  0.008733  0.062276  1.272623   \n",
       " 93693198  0.133796  0.158037  0.450134  0.069079  2.029905  0.160878   \n",
       " 95714813  0.016914  0.019978  0.056903  0.008733  0.062276  0.785779   \n",
       " 97686953  0.133796  0.158037  0.450134  0.069079  0.492634  0.160878   \n",
       " 97887921  0.016914  0.019978  0.056903  0.008733  0.062276  0.785779   \n",
       " \n",
       "               3C14      3C15      3C16       3C17  \n",
       " 3204944   0.177691  0.069696  0.148776   0.193434  \n",
       " 3634462   0.067963  0.026657  0.056903   0.073984  \n",
       " 7942838   0.537618  0.210870  0.450134   1.708670  \n",
       " 9661400   4.444769  0.573601  3.721492   0.206672  \n",
       " 11140926  1.164123  2.190082  1.025966   1.267264  \n",
       " ...            ...       ...       ...        ...  \n",
       " 93253491  0.067963  0.026657  0.056903   0.073984  \n",
       " 93693198  0.537618  0.210870  0.450134   1.708670  \n",
       " 95714813  0.067963  0.026657  0.056903   0.073984  \n",
       " 97686953  0.537618  0.210870  2.221563   1.708670  \n",
       " 97887921  0.067963  0.026657  0.056903  13.516427  \n",
       " \n",
       " [68 rows x 16 columns],\n",
       " 'var_estimates_students': 3204944     2.506535\n",
       " 3634462     3.467623\n",
       " 7942838     1.399433\n",
       " 9661400    -0.712903\n",
       " 11140926    0.626857\n",
       "               ...   \n",
       " 93253491    3.467623\n",
       " 93693198    1.399433\n",
       " 95714813    3.467623\n",
       " 97686953    1.399433\n",
       " 97887921    3.467623\n",
       " Length: 68, dtype: float64,\n",
       " 'var_estimates_items': 3C02   -1.595794\n",
       " 3C03   -0.445495\n",
       " 3C04   -2.037147\n",
       " 3C05    1.556001\n",
       " 3C06   -0.157082\n",
       " 3C07   -1.595794\n",
       " 3C08   -0.612010\n",
       " 3C09   -0.445495\n",
       " 3C10    0.601222\n",
       " 3C11   -1.273074\n",
       " 3C12    0.691444\n",
       " 3C13    3.226543\n",
       " 3C14    0.778825\n",
       " 3C15   -0.157082\n",
       " 3C16    0.601222\n",
       " 3C17    0.863717\n",
       " dtype: float64,\n",
       " 'outfit_students': 3204944     0.502388\n",
       " 3634462     2.429643\n",
       " 7942838     0.873969\n",
       " 9661400     1.402347\n",
       " 11140926    0.621666\n",
       "               ...   \n",
       " 93253491    0.117133\n",
       " 93693198    0.859334\n",
       " 95714813    0.500218\n",
       " 97686953    0.468718\n",
       " 97887921    0.926858\n",
       " Length: 68, dtype: float64,\n",
       " 'outfit_items': 3C02    0.748892\n",
       " 3C03    0.873447\n",
       " 3C04    0.545228\n",
       " 3C05    1.100443\n",
       " 3C06    2.595868\n",
       " 3C07    0.482246\n",
       " 3C08    1.505799\n",
       " 3C09    0.747376\n",
       " 3C10    0.782888\n",
       " 3C11    0.307784\n",
       " 3C12    1.008138\n",
       " 3C13    0.956326\n",
       " 3C14    0.913633\n",
       " 3C15    0.722260\n",
       " 3C16    1.084689\n",
       " 3C17    0.960984\n",
       " dtype: float64,\n",
       " 'infit_students': 3204944     0.756920\n",
       " 3634462     1.531275\n",
       " 7942838     1.032024\n",
       " 9661400     1.443092\n",
       " 11140926    0.781186\n",
       "               ...   \n",
       " 93253491    0.455613\n",
       " 93693198    1.014847\n",
       " 95714813    1.264126\n",
       " 97686953    0.679823\n",
       " 97887921    1.419768\n",
       " Length: 68, dtype: float64,\n",
       " 'infit_items': 3C02    0.922975\n",
       " 3C03    1.035335\n",
       " 3C04    1.025784\n",
       " 3C05    1.082494\n",
       " 3C06    1.339928\n",
       " 3C07    0.911637\n",
       " 3C08    0.966588\n",
       " 3C09    0.900879\n",
       " 3C10    0.887282\n",
       " 3C11    0.757321\n",
       " 3C12    1.069704\n",
       " 3C13    0.927352\n",
       " 3C14    1.017850\n",
       " 3C15    0.970689\n",
       " 3C16    1.063697\n",
       " 3C17    0.916934\n",
       " dtype: float64,\n",
       " 'bad_infit_items': 3C06    1.339928\n",
       " dtype: float64,\n",
       " 'bad_infit_students': 3634462     1.531275\n",
       " 9661400     1.443092\n",
       " 11871185    1.531275\n",
       " 14591907    1.531275\n",
       " 15830791    1.555520\n",
       " 15917802    1.473189\n",
       " 16961601    1.355046\n",
       " 17437695    1.339491\n",
       " 18927351    1.597956\n",
       " 35858306    1.481639\n",
       " 36514549    1.596940\n",
       " 57597189    1.650365\n",
       " 63312335    1.458860\n",
       " 69542440    1.496051\n",
       " 97887921    1.419768\n",
       " dtype: float64,\n",
       " 'bad_outfit_items': 3C06    2.595868\n",
       " 3C08    1.505799\n",
       " dtype: float64,\n",
       " 'bad_outfit_students': 3634462     2.429643\n",
       " 9661400     1.402347\n",
       " 11871185    2.429643\n",
       " 14591907    2.429643\n",
       " 14865762    2.262519\n",
       " 15830791    3.780883\n",
       " 15917802    1.557513\n",
       " 18863085    1.542314\n",
       " 35858306    2.398051\n",
       " 36514549    2.590849\n",
       " 57597189    1.548059\n",
       " 81211521    1.306045\n",
       " 91851188    1.534696\n",
       " dtype: float64,\n",
       " 'exam_num_and_form': '3C',\n",
       " 'true_false_df':           3C01  3C02  3C03  3C04  3C05  3C06  3C07  3C08  3C09  3C10  3C11  \\\n",
       " id                                                                           \n",
       " 3204944      1     1     1     1     1     1     1     1     1     1     1   \n",
       " 3634462      1     1     1     1     1     0     1     1     1     1     1   \n",
       " 7942838      1     1     1     1     1     1     1     1     0     0     1   \n",
       " 9661400      1     0     0     1     0     1     1     0     0     0     0   \n",
       " 11140926     1     1     1     1     0     1     1     1     1     0     1   \n",
       " ...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       " 93253491     1     1     1     1     1     1     1     1     1     1     1   \n",
       " 93693198     1     1     0     1     1     1     1     1     1     1     1   \n",
       " 95714813     1     1     1     1     0     1     1     1     1     1     1   \n",
       " 97686953     1     1     1     1     0     1     1     1     1     1     1   \n",
       " 97887921     1     1     1     1     1     1     1     1     1     1     1   \n",
       " \n",
       "           3C12  3C13  3C14  3C15  3C16  3C17  \n",
       " id                                            \n",
       " 3204944      0     0     1     1     1     1  \n",
       " 3634462      1     1     1     1     1     1  \n",
       " 7942838      1     0     1     1     1     0  \n",
       " 9661400      1     0     1     0     1     0  \n",
       " 11140926     0     0     1     0     0     1  \n",
       " ...        ...   ...   ...   ...   ...   ...  \n",
       " 93253491     1     0     1     1     1     1  \n",
       " 93693198     0     0     1     1     1     0  \n",
       " 95714813     1     1     1     1     1     1  \n",
       " 97686953     1     0     1     1     0     0  \n",
       " 97887921     1     1     1     1     1     0  \n",
       " \n",
       " [73 rows x 17 columns]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_rasch_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs_from_list_on_index(list_of_dfs):\n",
    "    if len(list_of_dfs) == 0:\n",
    "        joined_dfs=pd.DataFrame()\n",
    "    elif len(list_of_dfs) == 1:\n",
    "        joined_dfs=list_of_dfs[0]\n",
    "    else:\n",
    "        first_df=list_of_dfs.pop(0)\n",
    "        joined_dfs=first_df.join(list_of_dfs, how='inner')\n",
    "    return joined_dfs\n",
    "\n",
    "def build_rasch_sheets(list_of_rasch_dicts):\n",
    "    list_of_student_dfs=[]\n",
    "    list_of_item_dfs=[]\n",
    "    for rasch_dict in list_of_rasch_dicts:\n",
    "        student_partial_df_list=[]\n",
    "        for key in ['var_estimates_students', 'outfit_students', 'infit_students']:\n",
    "            temp_partial_student_df=pd.DataFrame(rasch_dict[key], columns=[key])\n",
    "            student_partial_df_list.append(temp_partial_student_df)\n",
    "        temp_student_df=join_dfs_from_list_on_index(student_partial_df_list)\n",
    "        temp_standard_error=math.sqrt(2/len(temp_student_df))\n",
    "\n",
    "        temp_student_df['is_outfit_outlier']=(temp_student_df['outfit_students'] > 1+2*temp_standard_error) \n",
    "        temp_student_df['is_infit_outlier']=(temp_student_df['infit_students'] > 1+2*temp_standard_error)\n",
    "        temp_student_df=temp_student_df.astype({'is_outfit_outlier': 'int', 'is_infit_outlier': 'int'})\n",
    "\n",
    "        list_of_student_dfs.append(temp_student_df)\n",
    "\n",
    "        item_partial_df_list=[]\n",
    "        for key in ['var_estimates_items', 'outfit_items', 'infit_items']:\n",
    "            temp_partial_item_df=pd.DataFrame(rasch_dict[key], columns=[key])\n",
    "            item_partial_df_list.append(temp_partial_item_df)\n",
    "        temp_item_df=join_dfs_from_list_on_index(item_partial_df_list)\n",
    "\n",
    "        temp_item_df['is_outfit_outlier']=(temp_item_df['outfit_items'] > 1+2*temp_standard_error) \n",
    "        temp_item_df['is_infit_outlier']=(temp_item_df['infit_items'] > 1+2*temp_standard_error)\n",
    "        temp_item_df=temp_item_df.astype({'is_outfit_outlier': 'int', 'is_infit_outlier': 'int'})\n",
    "\n",
    "        list_of_item_dfs.append(temp_item_df)\n",
    "\n",
    "    rasch_students_df=pd.concat(list_of_student_dfs)\n",
    "    rasch_students_df.index.name='student_id'\n",
    "\n",
    "    rasch_items_df=pd.concat(list_of_item_dfs)\n",
    "    rasch_items_df.index.name='question_id'\n",
    "    \n",
    "    return [rasch_students_df, rasch_items_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasch_student_results_df, rasch_item_results_df = build_rasch_sheets(list_of_rasch_dicts)\n",
    "\n",
    "base_dir=os.getcwd().replace('Item Response Theory Analysis', '')\n",
    "database_file_path=f\"{base_dir}/question_database_schema.xlsx\"\n",
    "with pd.ExcelWriter(database_file_path, engine=\"openpyxl\", mode='a', if_sheet_exists='replace') as writer:\n",
    "    rasch_student_results_df.to_excel(writer, sheet_name='rasch_students')\n",
    "    rasch_item_results_df.to_excel(writer, sheet_name='rasch_questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasch_item_results_df.sort_values(by='question_id', axis=0, inplace=True)\n",
    "bad_infit_df=rasch_item_results_df[rasch_item_results_df['is_infit_outlier'] == 1].dropna()\n",
    "bad_outfit_df=rasch_item_results_df[rasch_item_results_df['is_outfit_outlier'] == 1].dropna()\n",
    "\n",
    "print(len(bad_outfit_df.index))\n",
    "print(bad_outfit_df.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
