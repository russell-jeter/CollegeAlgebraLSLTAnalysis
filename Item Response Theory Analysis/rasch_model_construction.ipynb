{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_excel(\"../question_database_schema.xlsx\", sheet_name=\"student_question_responses\")\n",
    "key_df = pd.read_excel(\"../question_database_schema.xlsx\", sheet_name=\"answer_choices\")\n",
    "key_df = key_df[key_df['is_distractor'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create single exam/version df for Rasch modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions to form 0/1 dataframe with each row being a student and each column being a single exam/version question\n",
    "def exam_num_ver_df(num_and_ver, df):\n",
    "    exam_mask = df.apply(lambda x: x['question_id'].startswith(num_and_ver), axis=1)\n",
    "    exam_df = df[exam_mask]\n",
    "    return exam_df\n",
    "\n",
    "def questions_to_columns(df):\n",
    "    list_of_unique_id_dicts=[]\n",
    "    for unique_id in df['student_id'].unique():\n",
    "        unique_id_df = df[df['student_id'] == unique_id]\n",
    "        temp_dict={'id': unique_id}\n",
    "\n",
    "        question_list = unique_id_df['question_id'].tolist()\n",
    "        selection_list = unique_id_df['selected_option'].tolist()\n",
    "        \n",
    "        for index in range(0, len(question_list)):\n",
    "            temp_dict[question_list[index]]=selection_list[index]\n",
    "        \n",
    "        list_of_unique_id_dicts.append(temp_dict)\n",
    "\n",
    "    restructured_df=pd.DataFrame(list_of_unique_id_dicts)\n",
    "    restructured_df=restructured_df.set_index('id', drop=True)\n",
    "    bad_question=['4A01', '4B01', '4C01']\n",
    "    for bad_q_label in bad_question:\n",
    "        if bad_q_label in restructured_df.keys():\n",
    "            restructured_df.drop(bad_q_label, axis=1, inplace=True)\n",
    "    return restructured_df\n",
    "\n",
    "def create_num_ver_key_dict(num_and_ver, key_df):\n",
    "    exam_key_df = exam_num_ver_df(num_and_ver, key_df)\n",
    "\n",
    "    question_ids = exam_key_df['question_id'].tolist()\n",
    "\n",
    "    answer_series=exam_key_df['option_id'].replace({'A': '1', 'B': '2', 'C': '3', 'D': '4', 'E': '5'}) # avoids downcast warning\n",
    "    answer_series=answer_series.astype(int) #manually forces downcasting\n",
    "    answers = answer_series.tolist()\n",
    "\n",
    "    key_dict = {}\n",
    "    for index in range(0, len(question_ids)):\n",
    "        key_dict[question_ids[index]] = answers[index]\n",
    "    return key_dict\n",
    "\n",
    "def compare_row_to_dict(row, dict_to_compare):\n",
    "    return row.eq(pd.Series(dict_to_compare))\n",
    "\n",
    "def true_false_df(df, key_dict):\n",
    "    tf_df = df.apply(compare_row_to_dict, axis=1, args=(key_dict,))\n",
    "    return tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions to manipulate raw dfs to create dfs by exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove students & questions with 100% scores and 0% scores\n",
    "def remove_issue_scores(df):\n",
    "    temp_df = df.copy()\n",
    "    len_of_key = len(df.keys())\n",
    "    temp_df['score']=temp_df.sum(axis=1)\n",
    "\n",
    "    if len_of_key in temp_df['score'].unique():\n",
    "        drop_list_100s=temp_df[temp_df['score'] == len_of_key].index.to_list()\n",
    "        temp_df.drop(drop_list_100s, inplace=True)\n",
    "        print(f'{len(drop_list_100s)} 100% scores were dropped.')\n",
    "    if 0 in temp_df['score'].unique():\n",
    "        drop_list_0s=temp_df[temp_df['score'] == 0].index.to_list()\n",
    "        temp_df.drop(drop_list_0s, inplace=True)\n",
    "        print(f'{len(drop_list_0s)} 0% scores were dropped.')\n",
    "    temp_df.drop(['score'], axis=1, inplace=True)\n",
    "\n",
    "    question_score_series=temp_df.mean(axis=0)\n",
    "    \n",
    "    question_0_score_series=question_score_series.where(question_score_series == 0).dropna()\n",
    "    if len(question_0_score_series) > 0:\n",
    "        q0_index_list=question_0_score_series.index.to_list()\n",
    "        temp_df.drop(q0_index_list, axis=1, inplace=True)\n",
    "\n",
    "    question_100_score_series=question_score_series.where(question_score_series == 1).dropna()\n",
    "    if len(question_100_score_series) > 0:\n",
    "        q100_index_list=question_100_score_series.index.to_list()\n",
    "        temp_df.drop(q100_index_list, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "def collect_all_exam_numbers_and_forms(df):\n",
    "    all_question_ids=df['question_id'].tolist()\n",
    "    all_exam_numbers_and_forms=list(set([x[0:2] for x in all_question_ids]))\n",
    "    return all_exam_numbers_and_forms\n",
    "\n",
    "def create_true_false_for_all_exams(full_df, key_df, all_exam_numbers_and_forms):\n",
    "    list_of_tf_dfs=[]\n",
    "    for exam_num_and_form in all_exam_numbers_and_forms:\n",
    "        temp_exam_df=exam_num_ver_df(exam_num_and_form, full_df)\n",
    "        temp_exam_responses_df=questions_to_columns(temp_exam_df)\n",
    "        temp_exam_answer_key=create_num_ver_key_dict(exam_num_and_form, key_df)\n",
    "        temp_exam_tf_df=true_false_df(temp_exam_responses_df, temp_exam_answer_key).astype(int)\n",
    "        list_of_tf_dfs.append({'exam_num_and_form': exam_num_and_form, 'true_false_df': temp_exam_tf_df})\n",
    "    return list_of_tf_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions for Rasch calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ability_estimate(row):\n",
    "    return math.log(row['avg_student_score'] / (1 - row['avg_student_score']))\n",
    "\n",
    "def difficulty_estimate(col):\n",
    "    return math.log((1 - col['avg_question_score'] ) / col['avg_question_score'])\n",
    "\n",
    "def approximate_ability_and_difficulty(df):\n",
    "    temp_df=df.copy()\n",
    "    temp_df['avg_student_score']=temp_df.mean(axis=1)\n",
    "    theta_s=temp_df.apply(ability_estimate, axis=1).tolist()\n",
    "    temp_df.drop(['avg_student_score'], axis=1, inplace=True)\n",
    "\n",
    "    temp_df.loc['avg_question_score'] = temp_df.mean(axis=0)\n",
    "    beta_i_non_normal = temp_df.apply(difficulty_estimate, axis=0)\n",
    "    temp_df.drop(['avg_question_score'], inplace=True)\n",
    "    avg_beta_i = beta_i_non_normal.mean()\n",
    "\n",
    "    beta_i = beta_i_non_normal - avg_beta_i\n",
    "    beta_i_keys=beta_i.keys().tolist() # Question names for dict keys\n",
    "\n",
    "    return {'beta_i_keys': beta_i_keys, 'beta_i': beta_i, 'theta_s': theta_s}\n",
    "\n",
    "def iterate_variable_estimates(variable_estimates_dict, variance_df, residuals_df):\n",
    "    beta_i=variable_estimates_dict['beta_i']\n",
    "    beta_i_keys=variable_estimates_dict['beta_i_keys']\n",
    "    theta_s=variable_estimates_dict['theta_s']\n",
    "\n",
    "    new_beta_i=[]\n",
    "    for beta_index in range(0, len(beta_i)):\n",
    "        temp_key=beta_i_keys[beta_index]\n",
    "        residual_col_sum=residuals_df[temp_key].sum()\n",
    "        variance_col_sum=variance_df[temp_key].sum()\n",
    "        temp_new_beta = beta_i[beta_index] - (residual_col_sum / variance_col_sum)\n",
    "        new_beta_i.append(temp_new_beta)\n",
    "\n",
    "    temp_new_theta_s=[]\n",
    "    for theta_index in range(0, len(theta_s)):\n",
    "        residual_row_sum=residuals_df.loc[theta_index].sum()\n",
    "        variance_row_sum=variance_df.loc[theta_index].sum()\n",
    "        temp_new_theta = theta_s[theta_index] + (residual_row_sum/variance_row_sum)\n",
    "        temp_new_theta_s.append(temp_new_theta)\n",
    "    theta_mean=statistics.fmean(temp_new_theta_s)\n",
    "    new_theta_s=[x-theta_mean for x in temp_new_theta_s]\n",
    "\n",
    "    return {'beta_i_keys': beta_i_keys, 'beta_i': new_beta_i, 'theta_s': new_theta_s}\n",
    "\n",
    "def calc_expected_values(variable_estimates_dict):\n",
    "    beta_i_keys=variable_estimates_dict['beta_i_keys']\n",
    "    beta_i=variable_estimates_dict['beta_i']\n",
    "    theta_s=variable_estimates_dict['theta_s']\n",
    "\n",
    "    list_of_ev_dicts=[]\n",
    "    for theta_index in range(0, len(theta_s)):\n",
    "        temp_ev_dict={}\n",
    "        for beta_index in range(0, len(beta_i)):\n",
    "            exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index])\n",
    "            temp_ev_dict[beta_i_keys[beta_index]] = exp_vars / (1 + exp_vars)\n",
    "#            try:\n",
    "#                exp_vars=math.exp(theta_s[theta_index] - beta_i[beta_index])\n",
    "#                temp_ev_dict[beta_i_keys[beta_index]] = exp_vars / (1 + exp_vars)\n",
    "#            except OverflowError:\n",
    "#                temp_ev_dict[beta_i_keys[beta_index]] = 0\n",
    "        list_of_ev_dicts.append(temp_ev_dict)\n",
    "\n",
    "    ev_df=pd.DataFrame(list_of_ev_dicts)\n",
    "    return ev_df\n",
    "\n",
    "def calc_est_var(df):\n",
    "    return df.apply(lambda x: x*(1-x))\n",
    "\n",
    "def calc_sum_sqr_residuals(df):\n",
    "    temp_series_sum = df.sum(axis=1)\n",
    "    temp_series_sum = temp_series_sum.pow(2)\n",
    "    sum_of_sqrs = temp_series_sum.sum()\n",
    "    return sum_of_sqrs\n",
    "\n",
    "# NO USE RIGHT NOW\n",
    "def practice_multiplying_df(df):\n",
    "    # Take diff_est_normalized row, create df copy for each student, then multiply df by ability_est\n",
    "    beta_i=df.loc['diff_est_normalized'].copy().drop(['avg_student_score', 'ability_est'])\n",
    "    theta_s=df['ability_est'].copy().drop(['avg_question_score', 'diff_est_raw', 'diff_est_normalized']).reset_index(drop=True)\n",
    "    ev_df=pd.DataFrame([beta_i]*len(theta_s)).reset_index(drop=True)\n",
    "    ev_df=ev_df.multiply(theta_s, axis='index')\n",
    "    print(ev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasch calculation definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rasch_model(base_df):\n",
    "    student_ids=base_df.index.tolist()\n",
    "    first_iteration=1\n",
    "    sum_sqr_res=1\n",
    "    iteration_num=0\n",
    "    while sum_sqr_res > 0.0001:\n",
    "        if first_iteration==1:\n",
    "            iteration_num=1\n",
    "            first_iteration=0\n",
    "            variable_estimates_dict=approximate_ability_and_difficulty(base_df)\n",
    "        else:\n",
    "            iteration_num+=1\n",
    "            variable_estimates_dict=iterate_variable_estimates(variable_estimates_dict, est_var_ex_vals_df, residuals_df)\n",
    "        expected_values_df=calc_expected_values(variable_estimates_dict)\n",
    "        est_var_ex_vals_df=calc_est_var(expected_values_df)\n",
    "        base_df.index=expected_values_df.index\n",
    "        residuals_df=base_df-expected_values_df\n",
    "        sum_sqr_res=calc_sum_sqr_residuals(residuals_df)\n",
    "\n",
    "    fit_df=residuals_df.pow(2)/est_var_ex_vals_df\n",
    "    fit_df.index=student_ids\n",
    "\n",
    "    var_estimates_students=pd.Series(variable_estimates_dict['theta_s'], index=student_ids)\n",
    "    var_estimates_items=pd.Series(variable_estimates_dict['beta_i'], index=variable_estimates_dict['beta_i_keys'])\n",
    "\n",
    "    outfit_students=fit_df.mean(axis=1)\n",
    "    outfit_students.index=student_ids\n",
    "    outfit_items=fit_df.mean(axis=0)\n",
    "\n",
    "    infit_students=residuals_df.pow(2).sum(axis=1)/est_var_ex_vals_df.sum(axis=1)\n",
    "    infit_students.index=student_ids\n",
    "    infit_items=residuals_df.pow(2).sum(axis=0)/est_var_ex_vals_df.sum(axis=0)\n",
    "\n",
    "    bad_infit_items=infit_items.where(infit_items > 1.3).dropna()\n",
    "    bad_infit_students=infit_students.where(infit_students > 1.3).dropna()\n",
    "\n",
    "    bad_outfit_items=outfit_items.where(outfit_items > 1.3).dropna()\n",
    "    bad_outfit_students=outfit_students.where(outfit_students > 1.3).dropna()\n",
    "\n",
    "    return {'fit_df': fit_df, \n",
    "            'var_estimates_students': var_estimates_students, \n",
    "            'var_estimates_items': var_estimates_items, \n",
    "            'outfit_students': outfit_students, \n",
    "            'outfit_items': outfit_items,\n",
    "            'infit_students': infit_students,\n",
    "            'infit_items': infit_items,\n",
    "            'bad_infit_items': bad_infit_items,\n",
    "            'bad_infit_students': bad_infit_students, \n",
    "            'bad_outfit_items': bad_outfit_items,\n",
    "            'bad_outfit_students': bad_outfit_students\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Rasch for all exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 100% scores were dropped.\n",
      "3C02         NaN\n",
      "3C03         NaN\n",
      "3C04         NaN\n",
      "3C05         NaN\n",
      "3C06    1.339662\n",
      "3C07         NaN\n",
      "3C08         NaN\n",
      "3C09         NaN\n",
      "3C10         NaN\n",
      "3C11         NaN\n",
      "3C12         NaN\n",
      "3C13         NaN\n",
      "3C14         NaN\n",
      "3C15         NaN\n",
      "3C16         NaN\n",
      "3C17         NaN\n",
      "dtype: float64\n",
      "6 100% scores were dropped.\n",
      "1B01   NaN\n",
      "1B02   NaN\n",
      "1B03   NaN\n",
      "1B04   NaN\n",
      "1B05   NaN\n",
      "1B06   NaN\n",
      "1B07   NaN\n",
      "1B08   NaN\n",
      "1B09   NaN\n",
      "1B10   NaN\n",
      "1B11   NaN\n",
      "1B12   NaN\n",
      "1B13   NaN\n",
      "1B14   NaN\n",
      "1B15   NaN\n",
      "1B16   NaN\n",
      "dtype: float64\n",
      "4B02         NaN\n",
      "4B03         NaN\n",
      "4B04         NaN\n",
      "4B06         NaN\n",
      "4B07         NaN\n",
      "4B08         NaN\n",
      "4B09         NaN\n",
      "4B10         NaN\n",
      "4B11         NaN\n",
      "4B12         NaN\n",
      "4B13         NaN\n",
      "4B14         NaN\n",
      "4B15         NaN\n",
      "4B16         NaN\n",
      "4B17         NaN\n",
      "4B18         NaN\n",
      "4B19    1.357725\n",
      "4B20         NaN\n",
      "4B21         NaN\n",
      "4B22         NaN\n",
      "4B23         NaN\n",
      "4B24         NaN\n",
      "4B25         NaN\n",
      "4B26         NaN\n",
      "dtype: float64\n",
      "4A02         NaN\n",
      "4A03         NaN\n",
      "4A04         NaN\n",
      "4A05         NaN\n",
      "4A06         NaN\n",
      "4A07    1.392429\n",
      "4A08         NaN\n",
      "4A09         NaN\n",
      "4A10         NaN\n",
      "4A11         NaN\n",
      "4A12         NaN\n",
      "4A13         NaN\n",
      "4A14         NaN\n",
      "4A15         NaN\n",
      "4A16         NaN\n",
      "4A17         NaN\n",
      "4A18         NaN\n",
      "4A19         NaN\n",
      "4A20         NaN\n",
      "4A21         NaN\n",
      "4A22         NaN\n",
      "4A23         NaN\n",
      "4A24         NaN\n",
      "4A25         NaN\n",
      "4A26         NaN\n",
      "dtype: float64\n",
      "1 100% scores were dropped.\n",
      "1A01   NaN\n",
      "1A02   NaN\n",
      "1A03   NaN\n",
      "1A04   NaN\n",
      "1A05   NaN\n",
      "1A06   NaN\n",
      "1A07   NaN\n",
      "1A08   NaN\n",
      "1A09   NaN\n",
      "1A10   NaN\n",
      "1A11   NaN\n",
      "1A12   NaN\n",
      "1A13   NaN\n",
      "1A14   NaN\n",
      "1A15   NaN\n",
      "1A16   NaN\n",
      "dtype: float64\n",
      "4 100% scores were dropped.\n",
      "2A01    1.349655\n",
      "2A02         NaN\n",
      "2A03         NaN\n",
      "2A04         NaN\n",
      "2A05         NaN\n",
      "2A06         NaN\n",
      "2A07         NaN\n",
      "2A08         NaN\n",
      "2A09         NaN\n",
      "2A10         NaN\n",
      "2A11         NaN\n",
      "2A12         NaN\n",
      "2A13         NaN\n",
      "2A14         NaN\n",
      "2A15         NaN\n",
      "2A16         NaN\n",
      "dtype: float64\n",
      "4 100% scores were dropped.\n",
      "2C01    1.525962\n",
      "2C02         NaN\n",
      "2C03         NaN\n",
      "2C04         NaN\n",
      "2C05         NaN\n",
      "2C06    1.350851\n",
      "2C07         NaN\n",
      "2C08         NaN\n",
      "2C09         NaN\n",
      "2C10         NaN\n",
      "2C11         NaN\n",
      "2C12         NaN\n",
      "2C13         NaN\n",
      "2C14         NaN\n",
      "2C15         NaN\n",
      "2C16         NaN\n",
      "dtype: float64\n",
      "4 100% scores were dropped.\n",
      "3A01         NaN\n",
      "3A02         NaN\n",
      "3A03         NaN\n",
      "3A04         NaN\n",
      "3A05    1.301012\n",
      "3A06         NaN\n",
      "3A07         NaN\n",
      "3A08         NaN\n",
      "3A09         NaN\n",
      "3A10         NaN\n",
      "3A11         NaN\n",
      "3A12         NaN\n",
      "3A13         NaN\n",
      "3A14         NaN\n",
      "3A15         NaN\n",
      "3A16         NaN\n",
      "3A17         NaN\n",
      "dtype: float64\n",
      "1 100% scores were dropped.\n",
      "4C02   NaN\n",
      "4C03   NaN\n",
      "4C04   NaN\n",
      "4C05   NaN\n",
      "4C06   NaN\n",
      "4C07   NaN\n",
      "4C08   NaN\n",
      "4C09   NaN\n",
      "4C10   NaN\n",
      "4C11   NaN\n",
      "4C12   NaN\n",
      "4C13   NaN\n",
      "4C14   NaN\n",
      "4C15   NaN\n",
      "4C16   NaN\n",
      "4C17   NaN\n",
      "4C18   NaN\n",
      "4C19   NaN\n",
      "4C20   NaN\n",
      "4C21   NaN\n",
      "4C22   NaN\n",
      "4C23   NaN\n",
      "4C24   NaN\n",
      "4C25   NaN\n",
      "4C26   NaN\n",
      "dtype: float64\n",
      "3B01   NaN\n",
      "3B02   NaN\n",
      "3B03   NaN\n",
      "3B04   NaN\n",
      "3B05   NaN\n",
      "3B06   NaN\n",
      "3B07   NaN\n",
      "3B08   NaN\n",
      "3B09   NaN\n",
      "3B10   NaN\n",
      "3B11   NaN\n",
      "3B12   NaN\n",
      "3B13   NaN\n",
      "3B14   NaN\n",
      "3B15   NaN\n",
      "3B16   NaN\n",
      "3B17   NaN\n",
      "dtype: float64\n",
      "2 100% scores were dropped.\n",
      "2B01   NaN\n",
      "2B02   NaN\n",
      "2B03   NaN\n",
      "2B04   NaN\n",
      "2B05   NaN\n",
      "2B06   NaN\n",
      "2B07   NaN\n",
      "2B08   NaN\n",
      "2B09   NaN\n",
      "2B10   NaN\n",
      "2B11   NaN\n",
      "2B12   NaN\n",
      "2B13   NaN\n",
      "2B14   NaN\n",
      "2B15   NaN\n",
      "2B16   NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "all_exam_numbers_and_forms=collect_all_exam_numbers_and_forms(raw_df)\n",
    "list_of_tf_dfs=create_true_false_for_all_exams(raw_df, key_df, all_exam_numbers_and_forms)\n",
    "\n",
    "list_of_rasch_dicts=[]\n",
    "for exam_df in list_of_tf_dfs:\n",
    "    no_error_exam_df=remove_issue_scores(exam_df['true_false_df'])\n",
    "    rasch_dict=build_rasch_model(no_error_exam_df)\n",
    "    rasch_dict['exam_num_and_form']=exam_df['exam_num_and_form']\n",
    "    rasch_dict['true_false_df']=exam_df['true_false_df']\n",
    "    list_of_rasch_dicts.append(rasch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs_from_list_on_index(list_of_dfs):\n",
    "    if len(list_of_dfs) == 0:\n",
    "        joined_dfs=pd.DataFrame()\n",
    "    elif len(list_of_dfs) == 1:\n",
    "        joined_dfs=list_of_dfs[0]\n",
    "    else:\n",
    "        first_df=list_of_dfs.pop(0)\n",
    "        joined_dfs=first_df.join(list_of_dfs, how='inner')\n",
    "    return joined_dfs\n",
    "\n",
    "def build_rasch_sheets(list_of_rasch_dicts):\n",
    "    list_of_student_dfs=[]\n",
    "    list_of_item_dfs=[]\n",
    "    for rasch_dict in list_of_rasch_dicts:\n",
    "        student_partial_df_list=[]\n",
    "        for key in ['var_estimates_students', 'outfit_students', 'infit_students']:\n",
    "            temp_partial_student_df=pd.DataFrame(rasch_dict[key], columns=[key])\n",
    "            student_partial_df_list.append(temp_partial_student_df)\n",
    "        temp_student_df=join_dfs_from_list_on_index(student_partial_df_list)\n",
    "        list_of_student_dfs.append(temp_student_df)\n",
    "\n",
    "        item_partial_df_list=[]\n",
    "        for key in ['var_estimates_items', 'outfit_items', 'infit_items']:\n",
    "            temp_partial_item_df=pd.DataFrame(rasch_dict[key], columns=[key])\n",
    "            item_partial_df_list.append(temp_partial_item_df)\n",
    "        temp_item_df=join_dfs_from_list_on_index(item_partial_df_list)\n",
    "        list_of_item_dfs.append(temp_item_df)\n",
    "\n",
    "    rasch_students_df=pd.concat(list_of_student_dfs)\n",
    "    rasch_students_df.index.name='student_id'\n",
    "    rasch_students_df['is_outfit_outlier']=rasch_students_df['outfit_students'] > 1.3\n",
    "    rasch_students_df['is_infit_outlier']=rasch_students_df['infit_students'] > 1.3\n",
    "    rasch_students_df=rasch_students_df.astype({'is_outfit_outlier': 'int', 'is_infit_outlier': 'int'})\n",
    "\n",
    "    rasch_items_df=pd.concat(list_of_item_dfs)\n",
    "    rasch_items_df.index.name='question_id'\n",
    "    rasch_items_df['is_outfit_outlier']=rasch_items_df['outfit_items']>1.3\n",
    "    rasch_items_df['is_infit_outlier']=rasch_items_df['infit_items']>1.3\n",
    "    rasch_items_df=rasch_items_df.astype({'is_outfit_outlier': 'int', 'is_infit_outlier': 'int'})\n",
    "    \n",
    "    return [rasch_students_df, rasch_items_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student_id\n",
      "3204944     False\n",
      "3634462      True\n",
      "7942838     False\n",
      "9661400      True\n",
      "11140926    False\n",
      "            ...  \n",
      "95799545     True\n",
      "96301836    False\n",
      "96834233    False\n",
      "97686953    False\n",
      "99015981    False\n",
      "Name: outfit_students, Length: 886, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "rasch_student_results_df, rasch_item_results_df = build_rasch_sheets(list_of_rasch_dicts)\n",
    "\n",
    "base_dir=os.getcwd().replace('Item Response Theory Analysis', '')\n",
    "database_file_path=f\"{base_dir}/question_database_schema.xlsx\"\n",
    "with pd.ExcelWriter(database_file_path, engine=\"openpyxl\", mode='a', if_sheet_exists='replace') as writer:\n",
    "    rasch_student_results_df.to_excel(writer, sheet_name='rasch_students')\n",
    "    rasch_item_results_df.to_excel(writer, sheet_name='rasch_questions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
